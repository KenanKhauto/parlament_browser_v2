{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import spacy\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0, 0, 2, 2])\n",
      "tensor([[2.3486e-03, 9.9758e-01, 7.4774e-05],\n",
      "        [9.9020e-04, 9.9899e-01, 1.9995e-05],\n",
      "        [9.8840e-01, 1.1490e-02, 1.1099e-04],\n",
      "        [9.7940e-01, 2.0516e-02, 8.2444e-05],\n",
      "        [5.5865e-04, 1.2245e-03, 9.9822e-01],\n",
      "        [3.1925e-04, 9.1280e-04, 9.9877e-01]])\n"
     ]
    }
   ],
   "source": [
    "model_name = \"oliverguhr/german-sentiment-bert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "X_train = [\n",
    "    \"Mit keinem guten Ergebniss\",\"Das ist gar nicht mal so gut\",\n",
    "    \"Total awesome!\",\"nicht so schlecht wie erwartet\",\n",
    "    \"Der Test verlief positiv.\",\"Sie fährt ein grünes Auto.\"]\n",
    "\n",
    "t = \"\"\"nicht so schlecht wie erwartet\n",
    "\"\"\"\n",
    "batch = tokenizer(X_train, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(**batch)\n",
    "    label_ids = torch.argmax(output.logits, dim=1)\n",
    "    print(label_ids)\n",
    "    prediction_scores = F.softmax(output.logits, dim=1)\n",
    "    print(prediction_scores)\n",
    "    #labels = [model.config.id2label[label_id] for label_id in label_ids]\n",
    "    #print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US-Amerikaners LOC 258 272\n",
      "Kevin Hines PER 273 284\n",
      "Golden Gate Bridge LOC 459 477\n",
      "San Francisco LOC 481 494\n",
      "Sehr geehrte Frau Präsidentin!\n",
      "0\n",
      "30\n",
      "\n",
      "Meine Damen und Herren!\n",
      "31\n",
      "54\n",
      "\n",
      "Wie wichtig es ist, den tatsächlichen \n",
      "autonomen Willen einer vermeintlich suizidwilligen Person festzustellen, bevor ihm das todbringende Medikament \n",
      "verschrieben wird, veranschaulicht das Beispiel des US-Amerikaners Kevin Hines.\n",
      "55\n",
      "285\n",
      "\n",
      "Den jungen Mann, der an einer bipolaren \n",
      "Störung und schweren Depressionen leidet, hatte plötzlich ein starkes Gefühl ergriffen, jetzt sterben zu wollen.\n",
      "286\n",
      "439\n",
      "\n",
      "Er sprang von \n",
      "der Golden Gate Bridge in San Francisco – und überlebte, im Gegensatz zu den anderen 99 Prozent der gesprungenen Personen.\n",
      "440\n",
      "577\n",
      "\n",
      "Er selbst \n",
      "erzählt, dass er noch im freien Fall tief bereut habe, gesprungen zu sein\n",
      "\n",
      "578\n",
      "663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained German NER model\n",
    "#spacy.cli.download(\"de_core_news_lg\")\n",
    "nlp = spacy.load(\"de_core_news_lg\")\n",
    "\n",
    "# Process a text and extract named entities\n",
    "text = \"\"\"Sehr geehrte Frau Präsidentin! Meine Damen und Herren! Wie wichtig es ist, den tatsächlichen \n",
    "autonomen Willen einer vermeintlich suizidwilligen Person festzustellen, bevor ihm das todbringende Medikament \n",
    "verschrieben wird, veranschaulicht das Beispiel des US-Amerikaners Kevin Hines. Den jungen Mann, der an einer bipolaren \n",
    "Störung und schweren Depressionen leidet, hatte plötzlich ein starkes Gefühl ergriffen, jetzt sterben zu wollen. Er sprang von \n",
    "der Golden Gate Bridge in San Francisco – und überlebte, im Gegensatz zu den anderen 99 Prozent der gesprungenen Personen. Er selbst \n",
    "erzählt, dass er noch im freien Fall tief bereut habe, gesprungen zu sein\n",
    "\"\"\"\n",
    "doc = nlp(text)\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_, entity.start_char, entity.end_char)\n",
    "\n",
    "# for token in doc:\n",
    "#     print(token.text, token.pos_, token.dep_, token.head.text)\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)\n",
    "    print(sent.start_char)\n",
    "    print(sent.end_char)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mit keinem guten Ergebniss Das ist gar nicht mal so gut Total awesome! nicht so schlecht wie erwartet Der Test verlief positiv. Sie fährt ein grünes Auto.'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(X_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
